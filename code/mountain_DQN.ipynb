{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOeOmI+UF5DYEKWniVkFy/e"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip3 install gymnasium[classic_control]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vg8hoNMk5PGb","executionInfo":{"status":"ok","timestamp":1733065587530,"user_tz":-540,"elapsed":11546,"user":{"displayName":"JAEJUN LEE","userId":"02158505679312899958"}},"outputId":"f4301e1b-1b0a-4ac3-efdc-5b1514432c4a"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting gymnasium[classic_control]\n","  Downloading gymnasium-1.0.0-py3-none-any.whl.metadata (9.5 kB)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[classic_control]) (1.26.4)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[classic_control]) (3.1.0)\n","Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[classic_control]) (4.12.2)\n","Collecting farama-notifications>=0.0.1 (from gymnasium[classic_control])\n","  Downloading Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n","Requirement already satisfied: pygame>=2.1.3 in /usr/local/lib/python3.10/dist-packages (from gymnasium[classic_control]) (2.6.1)\n","Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n","Downloading gymnasium-1.0.0-py3-none-any.whl (958 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m958.1/958.1 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: farama-notifications, gymnasium\n","Successfully installed farama-notifications-0.0.4 gymnasium-1.0.0\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":575},"id":"Bcsv58rD5MZL","executionInfo":{"status":"error","timestamp":1733065605784,"user_tz":-540,"elapsed":18257,"user":{"displayName":"JAEJUN LEE","userId":"02158505679312899958"}},"outputId":"e94437bc-f69c-4ef6-bde1-e8a1610f8e81"},"outputs":[{"output_type":"stream","name":"stdout","text":["New best score: -32.36760248302778. Model saved.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n","  deprecation(\n","/usr/local/lib/python3.10/dist-packages/pygame/pkgdata.py:25: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n","  from pkg_resources import resource_stream, resource_exists\n","/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\n","Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n","  declare_namespace(pkg)\n","/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google.cloud')`.\n","Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n","  declare_namespace(pkg)\n","/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\n","Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n","  declare_namespace(pkg)\n"]},{"output_type":"error","ename":"NameError","evalue":"name 'agent' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-9876284df5be>\u001b[0m in \u001b[0;36m<cell line: 187>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-2-9876284df5be>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m                 \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m                 \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCategorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'agent' is not defined"]}],"source":["## 라이브러리 import\n","import gymnasium as gym\n","import collections\n","import random\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import pickle\n","import os\n","from gym.wrappers.record_video import RecordVideo\n","import matplotlib.pyplot as plt\n","\n","learning_rate = 0.005\n","gamma = 0.98\n","buffer_limit = 50000\n","batch_size = 64\n","\n","class ReplayBuffer():\n","    def __init__(self):\n","        self.buffer = collections.deque(maxlen=buffer_limit)\n","\n","    def put(self, transition):\n","        self.buffer.append(transition)\n","\n","    def sample(self, n):\n","        mini_batch = random.sample(self.buffer, n)\n","        s_lst, a_lst, r_lst, s_prime_lst, done_mask_lst = [], [], [], [], []\n","\n","        for transition in mini_batch:\n","            s, a, r, s_prime, done_mask = transition\n","            s_lst.append(s)\n","            a_lst.append([a])\n","            r_lst.append([r])\n","            s_prime_lst.append(s_prime)\n","            done_mask_lst.append([done_mask])\n","\n","        return torch.tensor(s_lst, dtype=torch.float), torch.tensor(a_lst), \\\n","               torch.tensor(r_lst), torch.tensor(s_prime_lst, dtype=torch.float), \\\n","               torch.tensor(done_mask_lst)\n","\n","    def size(self):\n","        return len(self.buffer)\n","\n","class Qnet(nn.Module):\n","    def __init__(self, input_dim, output_dim):\n","        super(Qnet, self).__init__()\n","        self.fc1 = nn.Linear(input_dim, 128)\n","        self.fc2 = nn.Linear(128, 128)\n","        self.fc3 = nn.Linear(128, output_dim)\n","\n","    def forward(self, x):\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n","\n","    def sample_action(self, obs, epsilon):\n","        out = self.forward(obs)\n","        coin = random.random()\n","        if coin < epsilon:\n","            return random.randint(0,1)\n","        else :\n","            return out.argmax().item()\n","\n","def train(q, q_target, memory, optimizer):\n","    for i in range(10):\n","        s,a,r,s_prime,done_mask = memory.sample(batch_size)\n","\n","        q_out = q(s)\n","        q_a = q_out.gather(1,a)\n","        max_q_prime = q_target(s_prime).max(1)[0].unsqueeze(1)\n","        target = r + gamma * max_q_prime * done_mask\n","        loss = F.smooth_l1_loss(q_a, target)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","def main():\n","    env = gym.make(\"MountainCar-v0\", render_mode=\"rgb_array\")\n","\n","    state_dim = env.observation_space.shape[0]\n","    action_dim = env.action_space.n\n","\n","    q = Qnet(state_dim, action_dim)\n","    q_target = Qnet(state_dim, action_dim)\n","    q_target.load_state_dict(q.state_dict())\n","    memory = ReplayBuffer()\n","\n","    best_score = -float('inf')\n","    print_interval = 1\n","    score = 0.0\n","    avg_scores = []\n","    optimizer = optim.Adam(q.parameters(), lr=learning_rate)\n","\n","    for n_epi in range(1000):\n","        epsilon = max(0.001, 0.1 - 0.0001 * (n_epi / 10))\n","        s, _ = env.reset()\n","        done = False\n","        episode_reward = 0\n","        t = 0\n","\n","        while not done:\n","            a = q.sample_action(torch.from_numpy(s).float(), epsilon)\n","            step_result = env.step(a)  # 반환 값을 변수로 저장\n","            if len(step_result) == 5:\n","                s_prime, r, terminated, truncated, info = step_result\n","            else:  # truncated가 없는 경우\n","                s_prime, r, terminated, info = step_result\n","                truncated = False\n","\n","            done = terminated or truncated  # 종료 조건 업데이트\n","\n","            position, velocity = s_prime\n","            if velocity < 0 and a == 0:\n","                r += 2\n","            elif velocity > 0 and a == 2:\n","                r += 2\n","            elif velocity < 0 and a == 2:\n","                r -= 1\n","            elif velocity > 0 and a == 0:\n","                r -= 1\n","            if position >= 0.5:\n","                r += 100\n","\n","            r += abs(velocity) * 0.1\n","            r += abs(position) * 0.1\n","            r += max(0, 200 - t) * 0.01\n","\n","            if done and position < 0.5:\n","                r -= 50\n","\n","            done_mask = 0.0 if done else 1.0\n","            memory.put((s, a, r, s_prime, done_mask))\n","            s = s_prime\n","            episode_reward += r\n","            t += 1\n","\n","            if done:\n","                break\n","\n","        score += episode_reward\n","        if memory.size() > 2000:\n","            train(q, q_target, memory, optimizer)\n","\n","        if score >= best_score:\n","            best_score = score\n","            torch.save(q.state_dict(), f\"dqn_mcar{n_epi}__.pth\")\n","            print(f\"New best score: {best_score}. Model saved.\")\n","\n","        if n_epi % print_interval == 0 and n_epi != 0:\n","            avg_score = score / print_interval\n","            avg_scores.append(avg_score)\n","            print(\"n_episode :{}, score : {:.1f}, n_buffer : {}, eps : {:.1f}%\".format(\n","                n_epi, score / print_interval, memory.size(), epsilon * 100))\n","            score = 0.0\n","\n","        if n_epi % 100 == 0:\n","            q_target.load_state_dict(q.state_dict())\n","\n","        video_env = RecordVideo(gym.make('MountainCar-v0', render_mode=\"rgb_array\"), video_folder=\"./dqn_videos\", episode_trigger=lambda e: True)\n","        for episode in range(10):\n","            observation, _ = video_env.reset()\n","            done = False\n","            while not done:\n","                prob = agent(torch.from_numpy(observation).float().to(device))\n","                m = Categorical(prob)\n","                action = m.sample()\n","                observation, _, done, info = video_env.step(action.item())\n","            print(f\"Recorded Episode {episode}\")\n","\n","        video_env.close()\n","\n","    env.close()\n","\n","    with open(\"dqn_scores.pkl\", \"wb\") as f:\n","        pickle.dump(avg_scores, f)\n","    print(\"DQN 학습 결과 저장 완료: dqn_scores.pkl\")\n","\n","    plt.plot(avg_scores)\n","    plt.xlabel('Episodes')\n","    plt.ylabel('Average Score')\n","    plt.title('Average Score vs Episodes')\n","    plt.show()\n","\n","if __name__ == '__main__':\n","    main()\n"]},{"cell_type":"code","source":[],"metadata":{"id":"uz1t4n3R5TGn"},"execution_count":null,"outputs":[]}]}